# Kyungmin's Feedback Implementation Summary

## Date: 2025-10-12

ê²½ë¯¼ë‹˜ì˜ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬í˜„í•œ ë‚´ìš© ì •ë¦¬

---

## âœ… Implemented Features

### 1. Error Recovery Hierarchy âš ï¸

**ê²½ë¯¼ë‹˜ ìš”ì²­ì‚¬í•­:**
> "Errorë“¤ì— ëŒ€í•´ ì˜ hierarchyë¥¼ êµ¬ì„±í•´ì•¼ í•˜ëŠ”ë°, SQLì´ ì˜ëª»ëœ syntax error ê²€ì‚¬ë¥¼ 1ì°¨ì ìœ¼ë¡œ í•˜ê³ , ì‚´ì•„ë‚¨ì€ ê²½ìš°ì— semantic errorë¥¼ 2ì°¨ë¡œ"

**êµ¬í˜„ ë‚´ìš©:**
```python
# model/progressive_executor.py
def execute_progressive(...):
    # 1st level: Syntax error check + retry
    sql, exec_result = self._generate_and_execute_with_retry(
        task, context, schema, max_syntax_retries=2
    )

    # 2nd level: Semantic error check (only if syntax OK)
    if exec_result['success']:
        reward_dict = self.reward_model.calculate_reward(...)
```

**íŠ¹ì§•:**
- **1ì°¨ (Syntax)**: ì‹¤í–‰í•´ì„œ syntax error â†’ ìµœëŒ€ 2íšŒ ì¬ì‹œë„ with error feedback
- **2ì°¨ (Semantic)**: Execution ì„±ê³µ ì‹œ â†’ LLMì´ ì˜ë¯¸ì  correctness íŒë‹¨
- Error messageë¥¼ promptì— í¬í•¨í•˜ì—¬ retry ì‹œ ê°œì„ 

**Reference**: https://www.vldb.org/pvldb/vol13/p1737-kim.pdf Figure 9

---

### 2. CHASE-SQL Baseline Implementation ğŸ“Š

**ê²½ë¯¼ë‹˜ ìš”ì²­ì‚¬í•­:**
> "CHASE-SQL í¬í•¨ baselineë“¤ í™•ì‹¤í•˜ê²Œ ì´ê¸¸ ê²ƒ ê°™ë‹¤ í•˜ë©´ ì—†ì´ ìš°ë¦¬ ê²ƒë§Œ ë‚˜ì¤‘ì— benchmark ì „ì²´ ëŒë ¤ì„œ ë” ì¢‹ì€ ìˆ«ì ë³´ì—¬ì£¼ë©´ ì¶©ë¶„í•˜ê³ ìš”"

**êµ¬í˜„ ë‚´ìš©:**
- `baseline/chase_sql.py`: CHASE-SQL one-shot approach
- `scripts/compare_baselines.py`: Head-to-head comparison

**ì°¨ì´ì :**
| Aspect | CHASE-SQL | Our Method |
|--------|-----------|------------|
| Approach | Query plan â†’ One-shot SQL generation | Query plan â†’ Progressive execution |
| Context | No context accumulation | Context accumulation per task |
| Error handling | Single attempt | Syntax retry + Semantic check |
| Iterations | 1 (one-shot) | Multiple (progressive) |

**ì‚¬ìš©ë²•:**
```bash
python scripts/compare_baselines.py \
    --data_path /path/to/bird \
    --limit 50 \
    --output comparison_results.json
```

---

### 3. Open-Source Model Support ğŸ¤–

**ê²½ë¯¼ë‹˜ ìš”ì²­ì‚¬í•­:**
> "ìš°ì„  í•™êµ í´ëŸ¬ìŠ¤í„°ì—ì„œ open-source ëª¨ë¸ì„ ì¨ì•¼í•  ê²ƒ ê°™ì•„ìš”. ì™¸ë¶€ API ë¹„ìš©ì— ëŒ€í•´ì„œëŠ” ë³´ìˆ˜ì ì´ë¼.."

**êµ¬í˜„ ë‚´ìš©:**
```python
# utils/llm_client.py - Unified LLMClient

# vLLM cluster (recommended)
client = LLMClient(
    model_name="deepseek-r1",  # or qwen2.5, llama-3.3
    base_url="http://cluster:8000/v1"
)

# HuggingFace Transformers
client = LLMClient(model_name="hf:Qwen/Qwen2.5-7B-Instruct")

# Ollama local
client = LLMClient(model_name="ollama:qwen2.5")
```

**ì§€ì› ëª¨ë¸:**
- âœ… DeepSeek-R1 (recommended by Kyungmin)
- âœ… Qwen2.5-72B-Instruct
- âœ… Llama-3.3-70B
- âœ… GPT-4o, Claude (for comparison)

**Cost strategy:**
- Primary: Open-source on school cluster (~$0)
- Development: Proprietary for prototyping (ê°œì¸ í™˜ê¸‰)
- Budget: $500 (ëª¨ë‹ˆí„°ë§í•˜ë‹¤ í•„ìš”í•˜ë©´ ëŠ˜ë¦´ ìˆ˜ ìˆìŒ)

---

### 4. Confidence Recalculation Strategy ğŸ¯

**ê²½ë¯¼ë‹˜ ë‹µë³€:**
> "Input stringì´ ì—…ë°ì´íŠ¸ ë  ë•Œë§ˆë‹¤ ê³„ì‚°í•˜ëŠ”ê²Œ ë§ëŠ”ê±°ê°™ê¸´ í•œë°, ë³„ë„ promptë¡œ ê°€ì ¸ì˜¬ ê²½ìš° ì´ê±´ ì¤„ì´ê¸´ í•´ì•¼ê² ë„¤ìš”"

**êµ¬í˜„ ë°©í–¥:**
```python
# Option A: Token logprobs ì‚¬ìš© (ì¶”í›„ êµ¬í˜„)
# GPT-4o API logprobsë¡œ confidence ê³„ì‚°

# Option B: ë³„ë„ prompt (í˜„ì¬)
# 2-3ê°œ taskë§ˆë‹¤ recalculateë¡œ ì¤„ì´ê¸°
```

**í˜„ì¬ ì„¤ì •:**
- Configì—ì„œ ì„¤ì • ê°€ëŠ¥í•˜ë„ë¡ ì¤€ë¹„
- Default: ë§¤ë²ˆ recalculate (ì •í™•ë„ ìš°ì„ )
- ë¹„ìš© ë¬¸ì œ ì‹œ ì¡°ì • ê°€ëŠ¥

---

### 5. Schema Linking Strategy ğŸ”—

**ê²½ë¯¼ë‹˜ ë‹µë³€:**
> "ë‹¨ìˆœí•˜ê²ŒëŠ” ì§€ê¸ˆ ê³µê°œëœ schema linking êµ¬í˜„ì„ ì“°ë˜, ì´ìª½ì„ íŒŒë ¤ë©´ ì‹¤ì œ ì˜ˆì œë“¤ ë¶„ì„í•˜ëŠ” ê±´ í•„ìš”í•´ë³´ì´ë„¤ìš”. + ë„¤ í˜„ì¬ ëª»í•˜ëŠ” ê²ƒì„ ì‹¤ì œë¡œ ë³´ì´ê³  í’€ë©´ ì´ê²ƒë§Œìœ¼ë¡œ ë…¼ë¬¸ì´ ë©ë‹ˆë‹¤"

**êµ¬í˜„ ë°©í–¥:**
1. ì¼ë‹¨ ê¸°ì¡´ SOTA schema linking ì‚¬ìš© (RESDSQL, DAIL-SQL)
2. Validation setì—ì„œ bottleneck íŒŒì•…
3. ë¬¸ì œ ìˆìœ¼ë©´ ê°œì„  (ë…¼ë¬¸ ê°€ëŠ¥ì„±)

**í˜„ì¬ ìƒíƒœ:**
- QueryPlanGeneratorì—ì„œ schema ì „ë‹¬
- ê°œì„  í•„ìš” ì‹œ ë³„ë„ component ì¶”ê°€ ì˜ˆì •

---

## ğŸ“‹ Current Status

### Completed âœ…
1. âœ… Error recovery hierarchy (syntax + semantic)
2. âœ… Syntax error retry mechanism (max 2 times)
3. âœ… CHASE-SQL baseline implementation
4. âœ… Open-source model support (vLLM, Transformers, Ollama)
5. âœ… Comparison framework (scripts/compare_baselines.py)

### In Progress ğŸ”„
1. Validation set creation (BIRD dev set 50-100 examples)
2. Confidence recalculation optimization
3. Schema linking analysis

### Pending â³
1. Multi-branch reasoning (MS rStar style)
   - **Decision**: ë‚˜ì¤‘ì— (ì¼ë‹¨ single branchë¡œ baseline í™•ë³´)
2. Token logprobs for confidence
3. Ground truth schema links
4. Full BIRD benchmark evaluation

---

## ğŸ¯ Next Steps

### Immediate (ì´ë²ˆ ì£¼)
1. **Validation set êµ¬ì„±**
   - BIRD devì—ì„œ 50-100 examples ì„ ì •
   - Stratified sampling (simple vs complex)

2. **Baseline ë¹„êµ ì‹¤í–‰**
   - Our method vs CHASE-SQL
   - Metrics: execution accuracy, semantic correctness, time

3. **Bottleneck íŒŒì•…**
   - Schema linking ì„±ëŠ¥
   - Syntax error ë¹ˆë„
   - Semantic error ë¹ˆë„

### Short-term (ë‹¤ìŒ ì£¼)
1. **Ablation study ì„¤ê³„**
   - Confidence scoreì˜ ì˜í–¥
   - Progressive execution vs one-shot
   - Error recoveryì˜ ì˜í–¥

2. **í•™êµ í´ëŸ¬ìŠ¤í„° ì…‹ì—…**
   - vLLM ì„œë²„ ì ‘ê·¼
   - DeepSeek-R1 or Qwen2.5 í…ŒìŠ¤íŠ¸

### Long-term (ì´í›„)
1. Multi-branch reasoning (if needed)
2. Schema linking ê°œì„  (if bottleneck)
3. Full BIRD benchmark
4. Paper writing

---

## ğŸ“Š Implementation Strategy (Kyungmin's guidance)

> "ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœë¡œ êµ¬í˜„ í›„ì—(ìƒˆë¡œìš´ ì•„ì´ë””ì–´ê°€ ì•„ë‹Œ ë¶€ë¶„ì€ ì´ì „ ì½”ë“œì—ì„œ ìµœëŒ€í•œ ê°€ì ¸ì˜¤ê³ ), ë‹¨ê³„ë³„ë¡œ, ì¦‰ confidence scoreê°€ ì •í™•ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, schema linkingì´ ë¯¸ì¹˜ëŠ” ì˜í–¥, syntax error recoveryê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë“±ì„ ë³´ê³  ê°œì„ í•˜ë©´ ë  ê²ƒ ê°™ì•„ìš”"

### Ablation Study Plan
1. **Baseline**: CHASE-SQL (one-shot)
2. **+Progressive**: Our progressive execution
3. **+Confidence**: With LLM confidence scores
4. **+Error Recovery**: With syntax/semantic recovery
5. **+Schema Linking**: With improved schema linking (if needed)

ê°ê°ì´ optimization subsectionì´ ë¨!

---

## ğŸ’¡ Key Insights from Kyungmin

### 1. Cost & Model Selection
- "Proprietary, large model ì•ˆì¨ë„ ì„±ëŠ¥ ë”°ë¼ì¡ì„ ìˆ˜ ìˆê³ , ì–¼ë§ˆë§Œí¼ ì‹œê°„ ë° ë¹„ìš© ì¤„ì¼ìˆ˜ìˆë‹¤ê³  ë³´ì—¬ì£¼ë©´ ë² ìŠ¤íŠ¸"
- "Taskê°€ ë§¤ìš° ì˜ê²Œ ìª¼ê°œì§„ ë•ì— ë¹„ìš©ì€ ë‚®ì€ë°, ì„±ëŠ¥ì€ ì˜ ë‚˜ì˜¬ê±° ê°™ê¸´ í•©ë‹ˆë‹¤"

### 2. Error Hierarchy
- "Syntax error ê°œì„ ì´ í›¨ì”¬ ì‰¬ìš´ë°(ëŒì•„ê°€ëŠ”ì§€/ì•„ë‹Œì§€ë§Œ íŒë‹¨í•˜ë©´ ë˜ë‹ˆê¹Œ)"
- "Semantic errorëŠ” ì‹¤ì œ NL question ì˜ë¯¸ì— í•©ë‹¹í•œ ê²°ê³¼ì¸ì§€ë¥¼ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤"

### 3. Evaluation Strategy
- "ë§¤ë²ˆ ì „ì²´ benchmarkë¥¼ ëŒë¦¬ê¸°ë³´ë‹¤, íŠ¹ì • validation setì„ ë½‘ê³  ì˜ ëœë‹¤ëŠ” í™•ì‹ ì´ ë“¤ ë•Œì—ë§Œ test setì„ í‚¤ì›Œë‚˜ê°€ë©´ ë  ê²ƒ ê°™ì•„ìš”"
- "$500ì¸ë°, ê³„ì† ëª¨ë‹ˆí„°ë§í•˜ë‹¤ í•„ìš”í•  ê²½ìš° ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"

### 4. Paper Strategy
- "ì‹¤ì œ bottleneckì´ ë¬´ì—‡ì¸ì§€ íŒŒì•… í›„ì— ìš°ë¦¬ ì•„ì´ë””ì–´ê°€ ì´ê±¸ ì˜ í•´ì†Œí•´ì£¼ëƒë¥¼ ë³´ê³ "
- "Schema linkingì„ ì˜í•œë‹¤ê±°ë‚˜ í•˜ë©´ ì´ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ë” ê°œì„ í•˜ê¸°ë³´ë‹¤ ë‹¤ë¥¸ ë¶€ë¶„ì„ íŒŒê³ "

---

## ğŸ“‚ File Structure

```
EPFL_hyunjun/
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ chase_sql.py              # CHASE-SQL one-shot baseline
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ MODEL_USAGE.md            # Open-source model usage guide
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ progressive_executor.py   # âœ¨ Error recovery added
â”‚   â””â”€â”€ semantic_reward.py        # Binary reward approach
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ compare_baselines.py      # Comparison framework
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ llm_client.py             # âœ¨ Multi-backend support
â””â”€â”€ KYUNGMIN_FEEDBACK_IMPLEMENTATION.md  # This file
```

---

## ğŸ”— References

1. Error hierarchy: https://www.vldb.org/pvldb/vol13/p1737-kim.pdf Figure 9
2. CHASE-SQL: 3-step reasoning approach
3. vLLM: https://github.com/vllm-project/vllm

---

**Last Updated**: 2025-10-12
**Status**: âœ… Core features implemented, ready for validation
